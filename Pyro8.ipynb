{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Pyro Bayesian Logistic Regression: 98.83%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load breast cancer dataset\n",
    "data = datasets.load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "X = X.astype(np.float32)\n",
    "\n",
    "# Preprocess the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Define the model and guide\n",
    "def model(X, y):\n",
    "    n_features = X.shape[1]\n",
    "    w = pyro.sample(\"w\", dist.Normal(torch.zeros(n_features), torch.ones(n_features)).to_event(1))\n",
    "    b = pyro.sample(\"b\", dist.Normal(0., 1.))\n",
    "    logits = torch.matmul(X, w) + b\n",
    "    with pyro.plate(\"data\", len(X)):\n",
    "        pyro.sample(\"obs\", dist.Bernoulli(logits=logits), obs=y)\n",
    "\n",
    "def guide(X, y):\n",
    "    n_features = X.shape[1]\n",
    "    w_loc = pyro.param(\"w_loc\", torch.zeros(n_features))\n",
    "    w_scale = pyro.param(\"w_scale\", torch.ones(n_features), constraint=dist.constraints.positive)\n",
    "    b_loc = pyro.param(\"b_loc\", torch.tensor(0.))\n",
    "    b_scale = pyro.param(\"b_scale\", torch.tensor(1.), constraint=dist.constraints.positive)\n",
    "\n",
    "    w = pyro.sample(\"w\", dist.Normal(w_loc, w_scale).to_event(1))\n",
    "    b = pyro.sample(\"b\", dist.Normal(b_loc, b_scale))\n",
    "\n",
    "\n",
    "# Perform Stochastic Variational Inference\n",
    "pyro.clear_param_store()\n",
    "optimizer = Adam({\"lr\": 0.01})\n",
    "svi = SVI(model, guide, optimizer, loss=Trace_ELBO())\n",
    "\n",
    "num_iterations = 1000\n",
    "for i in range(num_iterations):\n",
    "    svi.step(X_train_tensor, y_train_tensor)\n",
    "\n",
    "# Make predictions on the test set\n",
    "w_posterior = pyro.param(\"w_loc\")\n",
    "b_posterior = pyro.param(\"b_loc\")\n",
    "test_logits = torch.matmul(X_test_tensor, w_posterior) + b_posterior\n",
    "y_test_preds = torch.round(torch.sigmoid(test_logits)).detach().numpy()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_test_preds)\n",
    "print(\"Accuracy with Pyro Bayesian Logistic Regression: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO \t Training with 10 minibatches per epoch\n",
      "DEBUG \t step     0 loss = 12.6351\n",
      "DEBUG \t step   100 loss = 8.86371\n",
      "DEBUG \t step   200 loss = 9.06821\n",
      "DEBUG \t step   300 loss = 8.93611\n",
      "DEBUG \t step   400 loss = 9.163\n",
      "INFO \t Evaluating 1 minibatches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true ATE = 0.728\n",
      "naive ATE = 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG \t batch ate = 0.792038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated ATE = 0.792\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.contrib.cevae import CEVAE\n",
    "\n",
    "def generate_data(num_data, feature_dim):\n",
    "    z = dist.Bernoulli(0.5).sample([num_data])\n",
    "    x = dist.Normal(z, 5 * z + 3 * (1 - z)).sample([feature_dim]).t()\n",
    "    t = dist.Bernoulli(0.75 * z + 0.25 * (1 - z)).sample()\n",
    "    y = dist.Bernoulli(logits=3 * (z + 2 * (2 * t - 2))).sample()\n",
    "    t0_t1 = torch.tensor([[0.0], [1.0]])\n",
    "    y_t0, y_t1 = dist.Bernoulli(logits=3 * (z + 2 * (2 * t0_t1 - 2))).mean\n",
    "    true_ite = y_t1 - y_t0\n",
    "    return x, t, y, true_ite\n",
    "\n",
    "def main(args):\n",
    "    if args.cuda:\n",
    "        torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "\n",
    "    pyro.set_rng_seed(args.seed)\n",
    "    x_train, t_train, y_train, true_ite = generate_data(args.num_data, args.feature_dim)\n",
    "\n",
    "    pyro.set_rng_seed(args.seed)\n",
    "    pyro.clear_param_store()\n",
    "    cevae = CEVAE(\n",
    "        feature_dim=args.feature_dim,\n",
    "        latent_dim=args.latent_dim,\n",
    "        hidden_dim=args.hidden_dim,\n",
    "        num_layers=args.num_layers,\n",
    "        num_samples=10,\n",
    "    )\n",
    "    cevae.fit(\n",
    "        x_train,\n",
    "        t_train,\n",
    "        y_train,\n",
    "        num_epochs=args.num_epochs,\n",
    "        batch_size=args.batch_size,\n",
    "        learning_rate=args.learning_rate,\n",
    "        learning_rate_decay=args.learning_rate_decay,\n",
    "        weight_decay=args.weight_decay,\n",
    "    )\n",
    "\n",
    "    true_ate = true_ite.mean()\n",
    "    print(\"true ATE = {:0.3g}\".format(true_ate.item()))\n",
    "    naive_ate = y_train[t_train == 1].mean() - y_train[t_train == 0].mean()\n",
    "    print(\"naive ATE = {:0.3g}\".format(naive_ate))\n",
    "    if args.jit:\n",
    "        cevae = cevae.to_script_module()\n",
    "    est_ite = cevae.ite(x_train)\n",
    "    est_ate = est_ite.mean()\n",
    "    print(\"estimated ATE = {:0.3g}\".format(est_ate.item()))\n",
    "\n",
    "\n",
    "class Args:\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_data=1000,\n",
    "        feature_dim=5,\n",
    "        latent_dim=20,\n",
    "        hidden_dim=200,\n",
    "        num_layers=3,\n",
    "        num_epochs=50,\n",
    "        batch_size=100,\n",
    "        learning_rate=1e-3,\n",
    "        learning_rate_decay=0.1,\n",
    "        weight_decay=1e-4,\n",
    "        seed=1234567890,\n",
    "        jit=False,\n",
    "        cuda=False,\n",
    "    ):\n",
    "        self.num_data = num_data\n",
    "        self.feature_dim = feature_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.num_epochs = num_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.learning_rate_decay = learning_rate_decay\n",
    "        self.weight_decay = weight_decay\n",
    "        self.seed = seed\n",
    "        self.jit = jit\n",
    "        self.cuda = cuda\n",
    "\n",
    "args = Args()\n",
    "main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
